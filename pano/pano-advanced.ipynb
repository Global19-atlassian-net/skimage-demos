{
 "metadata": {
  "name": "",
  "signature": "sha256:89e2275e041fbb05eff697c5765a44d493d2c448da90b82b01c358d47f1d274c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# scikit-image advanced panorama demo\n",
      "\n",
      "Enhanced from the original demo as featured in [the scikit-image paper](https://peerj.com/articles/453/). This version does not require Enblend, instead stitching images along minimum-cost paths.\n",
      "\n",
      "This notebook may be found at https://github.com/scikit-image/scikit-image-demos"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###First things first\n",
      "\n",
      "Import NumPy, matplotlib, some necessary scikit-image functions, and define a utility function to compare multiple images with matplotlib"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from skimage import io, transform\n",
      "from skimage.color import rgb2gray\n",
      "\n",
      "def compare(*images, **kwargs):\n",
      "    \"\"\"\n",
      "    Utility function to display images side by side.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    image0, image1, image2, ... : ndarrray\n",
      "        Images to display.\n",
      "    labels : list\n",
      "        Labels for the different images.\n",
      "    \"\"\"\n",
      "    f, axes = plt.subplots(1, len(images), **kwargs)\n",
      "    axes = np.array(axes, ndmin=1)\n",
      "    \n",
      "    labels = kwargs.pop('labels', None)\n",
      "    if labels is None:\n",
      "        labels = [''] * len(images)\n",
      "    \n",
      "    for n, (image, label) in enumerate(zip(images, labels)):\n",
      "        axes[n].imshow(image, interpolation='nearest', cmap='gray')\n",
      "        axes[n].set_title(label)\n",
      "        axes[n].axis('off')\n",
      "    \n",
      "    plt.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load data\n",
      "\n",
      "The ``ImageCollection`` class provides an easy and efficient way to load and represent multiple images. Images in the ``ImageCollection`` are not read from disk until accessed.\n",
      "\n",
      "Load a series of images into an ``ImageCollection`` with a wildcard, as they share similar names. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pano_imgs = io.ImageCollection('data/JDW_03*')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inspect these images using the convenience function defined earlier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compare(*pano_imgs, figsize=(15, 10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Credit: Images of Private Arch in Arches National Park, USA, taken by Joshua D. Warner.<br>\n",
      "License: CC-BY 4.0"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#0. Pre-processing\n",
      "\n",
      "This stage usually involves one or more of the following:\n",
      "* Resizing, often downscaling with fixed aspect ratio\n",
      "* Conversion to grayscale, as many feature descriptors are not defined for color images\n",
      "* Cropping to region(s) of interest\n",
      "\n",
      "For convenience our example data is already resized smaller, and we won't bother cropping. However, they are presently in color so coversion to grayscale with `skimage.color.rgb2gray` is appropriate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pano0 = rgb2gray(pano_imgs[0])\n",
      "pano1 = rgb2gray(pano_imgs[1])\n",
      "pano2 = rgb2gray(pano_imgs[2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# View the results\n",
      "compare(pano0, pano1, pano2, figsize=(15, 10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For this demo,   Since the outer\n",
      "parts of these photographs do not comform well to such\n",
      "a model, we select only the central parts.  To\n",
      "further speed up the demonstration, images are downscaled\n",
      "to 25% of their original size."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 1. Feature detection and matching\n",
      "\n",
      "We need to estimate a projective transformation that relates these images together. The steps will be\n",
      "\n",
      "1. Define one image as a _target_ or _destination_ image, which will remain anchored while the others are warped\n",
      "2. Detect features in all three images\n",
      "3. Match features from left and right images against the features in the center, anchored image.\n",
      "\n",
      "In this three-shot series, the middle one (`pano1`) is the logical anchor point.\n",
      "\n",
      "We detect \"Oriented FAST and rotated BRIEF\" (ORB) features in both images:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.feature import ORB, match_descriptors, plot_matches\n",
      "\n",
      "# This number of keypoints is large enough for robust results, \n",
      "# but low enough to run within a few seconds. \n",
      "orb = ORB(n_keypoints=400, fast_threshold=0.05)\n",
      "\n",
      "orb.detect_and_extract(pano0)\n",
      "keypoints0 = orb.keypoints\n",
      "descriptors0 = orb.descriptors\n",
      "\n",
      "orb.detect_and_extract(pano1)\n",
      "keypoints1 = orb.keypoints\n",
      "descriptors1 = orb.descriptors\n",
      "\n",
      "orb.detect_and_extract(pano2)\n",
      "keypoints2 = orb.keypoints\n",
      "descriptors2 = orb.descriptors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Match descriptors between left/right images and the center\n",
      "matches01 = match_descriptors(descriptors0, descriptors1, cross_check=True)\n",
      "matches12 = match_descriptors(descriptors1, descriptors2, cross_check=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we inspect these matched features side-by-side using ``skimage.feature.plot_matches``. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
      "plot_matches(ax, pano0, pano1, keypoints0, keypoints1, matches01)\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most of these line up similarly, but it isn't perfect. There are a number of obvious outliers or false matches."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
      "plot_matches(ax, pano1, pano2, keypoints1, keypoints2, matches12)\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similar to above, decent signal but numerous false matches."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. Transform estimation\n",
      "\n",
      "To filter out the false matches, we apply RANdom SAMple Consensus (RANSAC), a powerful method of rejecting outliers available in ``skimage.transform.ransac``.  The transformation is estimated using an iterative process based on randomly chosen subsets, finally selecting the model which corresponds best with the majority of matches.\n",
      "\n",
      "We need to do this twice, once each for the transforms from left -> center and right -> center."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.transform import ProjectiveTransform\n",
      "from skimage.measure import ransac\n",
      "\n",
      "# Select keypoints from \n",
      "#   * source (image to be registered): pano0\n",
      "#   * target (reference image): pano1, our middle frame registration target\n",
      "src = keypoints0[matches01[:, 0]][:, ::-1]\n",
      "dst = keypoints1[matches01[:, 1]][:, ::-1]\n",
      "\n",
      "model_robust01, inliers01 = ransac((src, dst), ProjectiveTransform,\n",
      "                                   min_samples=4, residual_threshold=1, max_trials=300)\n",
      "\n",
      "# Select keypoints from \n",
      "#   * source (image to be registered): pano2\n",
      "#   * target (reference image): pano1, our middle frame registration target\n",
      "src = keypoints2[matches12[:, 1]][:, ::-1]\n",
      "dst = keypoints1[matches12[:, 0]][:, ::-1]\n",
      "\n",
      "model_robust12, inliers12 = ransac((src, dst), ProjectiveTransform,\n",
      "                                   min_samples=4, residual_threshold=1, max_trials=300)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `inliers` returned from RANSAC select the best subset of matches. How do the good matches look?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
      "plot_matches(ax, pano0, pano1, keypoints0, keypoints1, matches01[inliers01])\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
      "plot_matches(ax, pano1, pano2, keypoints1, keypoints2, matches12[inliers12])\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most of the false matches are rejected!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 3. Warping\n",
      "\n",
      "Next, we want to produce the panorama itself. To do that, we must _warp_, or transform, two of the three images so they will properly align with the stationary image.\n",
      "\n",
      "### Extent of output image\n",
      "The first step is to find the shape of the output image required to contain all three transformed images. To do this we consider the extents of all warped images."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.transform import SimilarityTransform\n",
      "\n",
      "# Shape of middle image, our registration target\n",
      "r, c = pano1.shape[:2]\n",
      "\n",
      "# Note that transformations take coordinates in (x, y) format,\n",
      "# not (row, column), in order to be consistent with most literature\n",
      "corners = np.array([[0, 0],\n",
      "                    [0, r],\n",
      "                    [c, 0],\n",
      "                    [c, r]])\n",
      "\n",
      "# Warp the image corners to their new positions\n",
      "warped_corners01 = model_robust01(corners)\n",
      "warped_corners12 = model_robust12(corners)\n",
      "\n",
      "# Find the extents of both the reference image and the warped\n",
      "# target image\n",
      "all_corners = np.vstack((warped_corners01, warped_corners12, corners))\n",
      "\n",
      "# The overally output shape will be max - min\n",
      "corner_min = np.min(all_corners, axis=0)\n",
      "corner_max = np.max(all_corners, axis=0)\n",
      "output_shape = (corner_max - corner_min)\n",
      "\n",
      "# Ensure integer shape with np.ceil and dtype conversion\n",
      "output_shape = np.ceil(output_shape[::-1]).astype(int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Apply estimated transforms\n",
      "\n",
      "Warp the images with `skimage.transform.warp` according to the estimated transformation model. A shift, or _translation_ is necessary as our middle image needs to be placed in the middle, so it isn't truly stationary.\n",
      "\n",
      "Values outside the input images are set to -1 to distinguish the \"background\", which is identified for later use.\n",
      "\n",
      "**Note:** ``warp`` takes the _inverse_ mapping as an input."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.transform import warp\n",
      "\n",
      "# This in-plane offset is the only necessary transformation for the middle image\n",
      "offset1 = SimilarityTransform(translation=-corner_min)\n",
      "\n",
      "# Warp pano0 on to pano1 using 3rd order interpolation\n",
      "pano0_warped = warp(pano0, (model_robust01 + offset1).inverse, order=3,\n",
      "                    output_shape=output_shape, cval=-1)\n",
      "pano0_mask = (pano0_warped != -1)  # Mask == 1 inside image\n",
      "pano0_warped[~pano0_mask] = 0      # Return background values to 0\n",
      "\n",
      "# Translate pano1 into place\n",
      "pano1_warped = warp(pano1, offset1.inverse, order=3,\n",
      "                    output_shape=output_shape, cval=-1)\n",
      "pano1_mask = (pano1_warped != -1)  # Mask == 1 inside image\n",
      "pano1_warped[~pano1_mask] = 0      # Return background values to 0\n",
      "\n",
      "# Warp pano2 on to pano1 \n",
      "pano2_warped = warp(pano2, (model_robust12 + offset1).inverse, order=3,\n",
      "                    output_shape=output_shape, cval=-1)\n",
      "pano2_mask = (pano2_warped != -1)  # Mask == 1 inside image\n",
      "pano2_warped[~pano2_mask] = 0      # Return background values to 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inspect the warped images:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compare(pano0_warped, pano1_warped, pano2_warped, figsize=(15, 10));"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#4. Combining images the easy (and bad) way\n",
      "\n",
      "This method simply \n",
      "\n",
      "1. sums the warped images\n",
      "2. tracks how many images overlapped to create each  point\n",
      "3. normalizes the result."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add the three images together. This could create dtype overflows!\n",
      "# We know they are are floating point images after warping, so it's OK.\n",
      "merged = (pano0_warped + pano1_warped + pano2_warped)\n",
      "\n",
      "# Track the overlap by adding the masks together\n",
      "overlap = (pano0_mask * 1.0 +  # Multiply by 1.0 for bool -> float conversion\n",
      "           pano1_mask + \n",
      "           pano2_mask)\n",
      "\n",
      "# Normalize through dividing by `overlap` - ensuring the minimum is 1\n",
      "normalized = merged / np.maximum(overlap, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, view the results!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(15, 12))\n",
      "ax.imshow(normalized, cmap='gray')\n",
      "plt.tight_layout()\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**What happened?!** Why are there nasty dark lines at boundaries?\n",
      "\n",
      "\n",
      "**This is an artifact (boundary effect) from the warping method**. When the image is warped with interpolation, the edges are affected by the surrounding background. We could have bright lines if we'd chosen `cval=1` in the `warp` calls, but regardless of choice there will always be discontinuities.\n",
      "\n",
      "...Unless you use `order=0` in `warp`, which is nearest neighbor. Then these edges are perfect (try it!). But who wants to be limited to an inferior interpolation method? Isn't there a better way?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#5. Stitching images along a minimum-cost path\n",
      "\n",
      "Let's step back a moment and consider: Is it even reasonable to blend pixels?\n",
      "\n",
      "Take a look at a difference image, which is just one image subtracted from the other."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(15,12))\n",
      "ax.imshow(pano0_warped - pano1_warped, cmap='gray')\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The surrounding flat gray is zero, so we see the overlap region matches fairly well in the middle... but off to the sides where things start to look a little embossed, a simple average would blur the result. _This is almost always the case for panoramas!_\n",
      "\n",
      "Instead, let's attempt to find a vertical path through this difference image which stays as close to zero as possible. If we use that to build a mask, defining a transition between images, the result should be seamless."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Minimum-Cost paths and `skimage.graph`\n",
      "\n",
      "The `skimage.graph` submodule allows you to start at any point on an array, and find the path to any other point which will _minimize_ the sum of values on the path.\n",
      "\n",
      "The overarching array is called a _cost array_, while the path found is a minimum-cost path or MCP.\n",
      "\n",
      "To accomplish this we need\n",
      "\n",
      "* Starting and ending points for the path\n",
      "* A cost array (a modified difference image)\n",
      "\n",
      "First, we'll find reasonable start- and end-points for a minimum-cost path separating the left or right from center image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x01 = int((offset1.translation[0] + pano1.shape[1] - 1) // 2)\n",
      "xmax = int(output_shape[0] - 1)\n",
      "mask_pts01 = [[0,    x01],\n",
      "              [xmax, x01]]\n",
      "\n",
      "x12 = int((output_shape[1] + offset1.translation[0] - 1) // 2)\n",
      "mask_pts12 = [[0,    x12],\n",
      "              [xmax, x12]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we generate the cost array. We will start with the difference, but must modify it further or it will take the trivial path around either image, as the background is all zeros!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Start with the absolute value of the difference image.\n",
      "# np.abs necessary because we don't want negative costs!\n",
      "diff01 = np.abs(pano0_warped - pano1_warped)\n",
      "\n",
      "# Penalize the areas around the diff\n",
      "diff01[~(pano0_mask &  pano1_mask)] = 1\n",
      "\n",
      "# Allow the path to \"slide\" along top and bottom edges to the optimal position\n",
      "diff01[0,  :output_shape[1] // 2] = 0\n",
      "diff01[-1, :output_shape[1] // 2] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we use `skimage.graph.route_through_array` to calculate an optimal path through the costs array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.graph import route_through_array\n",
      "\n",
      "pts, cost = route_through_array(diff01, mask_pts01[0], mask_pts01[1], fully_connected=True)\n",
      "pts = np.array(pts)  # Convert list of lists to 2d coordinate array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see how it worked."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(15, 15))\n",
      "ax.imshow(pano0_warped - pano1_warped, cmap='gray')\n",
      "ax.plot(pts[:, 1], pts[:, 0]);\n",
      "plt.tight_layout()\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That looks like a great seam to stitch these images together - the entire path looks very close to zero.\n",
      "\n",
      "**Note**: There is randomness in the RANSAC estimation, and as such, everyone will have a slightly different overlay. This means **your path will look different from mine, and different from your neighbor's**. _The awesome thing about MCP, though, is that everyone just calculated their best possible path to stitch together their unique transforms!_\n",
      "\n",
      "Now we place those points into a new, empty array to begin building our mask."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask0 = np.zeros_like(pano0_warped, dtype=np.uint8)\n",
      "mask0[pts[:, 0], pts[:, 1]] = 1\n",
      "\n",
      "fig, ax = plt.subplots(figsize=(11, 11))\n",
      "ax.imshow(mask0, cmap='gray')\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Filling the mask\n",
      "\n",
      "Our goal is to turn that path into a mask, which will be 1 where we want the left image to show through and zero elsewhere. We need to fill the left side of the mask with ones over to our path. To do that, we need to label the various contiguous regions in the image. We'll use `skimage.measure.label` for this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skimage.measure import label\n",
      "\n",
      "# Labeling starts at zero at point (0, 0)\n",
      "mask0[label(mask0, connectivity=1) == 0] = 1\n",
      "\n",
      "# The result\n",
      "plt.imshow(mask0, cmap='gray');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks great!\n",
      "\n",
      "Applying the same principles to images 1 and 2: first, build the cost array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Start with the absolute value of the difference image.\n",
      "# np.abs necessary because we don't want negative costs!\n",
      "diff12 = np.abs(pano1_warped - pano2_warped)\n",
      "\n",
      "# Penalize the areas around the diff\n",
      "diff12[~(pano2_mask &  pano1_mask)] = 1\n",
      "\n",
      "# New constraint: Do not overlap the region in mask0!\n",
      "diff12[mask0 > 0] = 20\n",
      "\n",
      "# Allow the path to \"slide\" along top and bottom edges to the optimal position\n",
      "diff01[0,  output_shape[1] // 2:] = 0\n",
      "diff01[-1, output_shape[1] // 2:] = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then compute the minimal cost path"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pts, cost = route_through_array(diff12, mask_pts12[0], mask_pts12[1], fully_connected=True)\n",
      "pts = np.array(pts)  # Convert list of lists to 2d coordinate array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Verify a reasonable result"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(15, 15))\n",
      "ax.imshow(pano1_warped - pano2_warped, cmap='gray')\n",
      "ax.plot([y for _, y in pts], [x for x, _ in pts]);\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Initialize the mask by placing the path in a new array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask2 = np.zeros_like(pano0_warped, dtype=np.uint8)\n",
      "mask2[pts[:, 0], pts[:, 1]] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fill the right side this time, again using `skimage.measure.label` - the label of interest is 2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask2[label(mask2, connectivity=1) == 2] = 1\n",
      "\n",
      "# The result\n",
      "plt.imshow(mask2, cmap='gray');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The final mask for the middle image is one of exclusion - it will be displayed everywhere `mask0` and `mask2` are not."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mask1 = ~(mask0 | mask2).astype(bool)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Convenience function to place masks in alpha channels"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_alpha(img, mask=None):\n",
      "    \"\"\"\n",
      "    Adds a masked alpha channel to an image.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    img : (M, N[, 3]) ndarray\n",
      "        Image data, should be rank-2 or rank-3 with RGB channels\n",
      "    mask : (M, N[, 3]) ndarray, optional\n",
      "        Mask to be applied. If None, the alpha channel is added\n",
      "        with full opacity assumed (1) at all locations.\n",
      "    \"\"\"\n",
      "    from skimage.color import gray2rgb\n",
      "    if mask is None:\n",
      "        mask = np.ones_like(img)\n",
      "        \n",
      "    if img.ndim == 2:\n",
      "        img = gray2rgb(img)\n",
      "    \n",
      "    return np.dstack((img, mask))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Obtain final, alpha blended individual images and inspect them"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pano0_final = add_alpha(pano0_warped, mask0)\n",
      "pano1_final = add_alpha(pano1_warped, mask1)\n",
      "pano2_final = add_alpha(pano2_warped, mask2)\n",
      "\n",
      "compare(pano0_final, pano1_final, pano2_final, figsize=(15, 15))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plot all three together and view the results!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(15, 12))\n",
      "\n",
      "# This is a perfect combination, but matplotlib's interpolation\n",
      "# makes it appear to have gaps. So we turn it off.\n",
      "ax.imshow(pano0_final, interpolation='none')\n",
      "ax.imshow(pano1_final, interpolation='none')\n",
      "ax.imshow(pano2_final, interpolation='none')\n",
      "\n",
      "fig.tight_layout()\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fantastic! No border effects! If you cropped this slightly, you'd never know where the seams were."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Bonus round: now, in color!\n",
      "\n",
      "We converted to grayscale for ORB feature detection, back in the initial **preprocessing** steps. Since we stored our transforms and masks, adding color is straightforward!\n",
      "\n",
      "First, transform the colored images"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Exact transforms as before, except\n",
      "#   * Operating on the color images\n",
      "#   * filling with cval=0 as we know the masks\n",
      "pano0_color = warp(pano_imgs[0], (model_robust01 + offset1).inverse, order=3,\n",
      "                    output_shape=output_shape, cval=0)\n",
      "\n",
      "pano1_color = warp(pano_imgs[1], offset1.inverse, order=3,\n",
      "                    output_shape=output_shape, cval=0)\n",
      "\n",
      "pano2_color = warp(pano_imgs[2], (model_robust12 + offset1).inverse, order=3,\n",
      "                    output_shape=output_shape, cval=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then apply the custom alpha channel masks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pano0_final = add_alpha(pano0_color, mask0)\n",
      "pano1_final = add_alpha(pano1_color, mask1)\n",
      "pano2_final = add_alpha(pano2_color, mask2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, plot the result!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots(figsize=(15, 12))\n",
      "\n",
      "ax.imshow(pano0_final, interpolation='none')\n",
      "ax.imshow(pano1_final, interpolation='none')\n",
      "ax.imshow(pano2_final, interpolation='none')\n",
      "\n",
      "fig.tight_layout()\n",
      "ax.axis('off');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Once more, from the top\n",
      "\n",
      "I hear what you're saying. \"But Josh, those were too easy! The panoramas had too much overlap! Does this still work in the real world?\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Go back to the top. Under \"Load Data\" replace the string `'data/JDW_03*'` with `'data/JDW_9*'`, and re-run all of the cells in order.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}